# ğŸ§ AudioSense â€“ Environmental Sound Classification (ESC) using CNNs

AudioSense is a complete machine-learning system for **classifying environmental sounds** using **Mel-spectrograms** and a **Convolutional Neural Network (CNN)**.  
This repository contains **two folders**:

- **backend/** â†’ ML model, preprocessing, training pipeline & inference API  
- **frontend/** â†’ Web UI for uploading audio & viewing predictions  

---

## ğŸš€ Features

- Converts raw audio (`.wav`) into **Mel-spectrograms**
- Deep learning classification using a **CNN**
- **ESC-50 (50 environmental classes)** support
- Built-in audio **data augmentation** (time shift, pitch shift, amplitude scaling)
- 5-Fold **cross-validation** compatible pipeline
- FastAPI backend API for inference
- React frontend for real-time predictions and visualization

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ prep.py          # Audio loading + spectrogram extraction
â”‚   â”‚   â”œâ”€â”€ model.py         # CNN architecture
â”‚   â”‚   â”œâ”€â”€ train.py         # Training script
â”‚   â”‚   â”œâ”€â”€ eval.py          # Evaluation
â”‚   â”‚   â””â”€â”€ main.py          # FastAPI inference server
â”‚   â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ README.md
```

---

## ğŸ§  Methodology Overview

### 1ï¸âƒ£ Audio Preprocessing  
- Load audio (`.wav`)
- Pad/trim to 5 seconds  
- Convert to **Mel-spectrogram (128Ã—Time)**  
- Normalize to 0â€“1

### 2ï¸âƒ£ CNN Model Architecture  
- 3 Convolutional blocks  
- BatchNorm + MaxPooling  
- Global Average Pooling  
- Dense (256) + Dropout  
- Output layer: `Softmax (50 classes)`

### 3ï¸âƒ£ Training  
- Categorical Crossentropy  
- Adam optimizer  
- EarlyStopping + Checkpointing  
- Optional data augmentation

### 4ï¸âƒ£ Inference  
- FastAPI endpoint:  
```
POST /predict
```
- Returns:
  - top class index  
  - top-5 probabilities  

---

## âš™ï¸ Installation & Setup

### **Backend Setup**
```bash
cd backend
pip install -r requirements.txt
uvicorn src.main:app --reload
```
API will run at:
```
http://localhost:8000
```

---

### **Frontend Setup**
```bash
cd frontend
npm install
npm start
```
App will run at:
```
http://localhost:3000
```

---

## ğŸ”¥ API Example Request
```bash
curl -X POST "http://localhost:8000/predict" \
     -F "file=@example.wav"
```

Sample response:
```json
{
  "prediction_index": 17,
  "top5": [
    {"index": 17, "probability": 0.92},
    {"index": 4,  "probability": 0.03},
    {"index": 12, "probability": 0.02}
  ]
}
```

---

## ğŸ“Š Dataset
This project uses the **ESC-50 Dataset** (50 classes, 2000 audio clips, 5-second each).

---

## ğŸ› ï¸ Future Improvements
- Real-time microphone input  
- Multi-feature fusion (MFCC + Spectrogram)  
- Larger audio datasets  
- Model quantization for mobile deployment  

---

## ğŸ¤ Contributing
Pull requests are welcome!  
If you'd like to improve training, augmentations, or UI, feel free to submit.

---

## ğŸ“œ License
MIT License Â© 2025

---

## ğŸ‘¤ Author
**Alaukik Patel**  
VII Semester â€“ CSE  
IIIT Senapati, Manipur
